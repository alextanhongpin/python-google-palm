{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58f2fdc6-57b5-4c61-8ccf-424aa6b090ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alextanhongpin/Documents/python/python-google-palm/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import google.generativeai as palm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e4c4845-8b30-45b8-8e42-02fc0e94b1ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "palm.configure(api_key=os.environ.get('PALM_API_KEY'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "30dff8fb-1ab9-4018-a3d4-1e14754cdc84",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = palm.get_model('models/text-bison-001')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d18154c-8e61-4dad-87e3-5b765c05766f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chain-of-thought:\n",
      "First find the total number of cats: 3 houses * 3 cats / house = 9 cats. Then multiply the number of cats by the number of mittens per cat to find the total number of mittens: 9 cats * 4 mittens / cat = 36 mittens. Then multiply the number of mittens by the length of yarn per mitten to find the total length of yarn used for mittens: 36 mittens * 7m / mitten = 252m. Then multiply the number of cats by the number of hats per cat to find the total number of hats: 9 cats * 1 hat / cat = 9 hats. Then multiply the number of hats by the length of yarn per hat to find the total length of yarn used for hats: 9 hats * 4m / hat = 36m. Then add the length of yarn used for mittens and hats to find the total length of yarn used: 252m + 36m = 288m.\n",
      "\n",
      "The answer should be 288\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "You are an expert at solving word problems.\n",
    "\n",
    "Solve the following problem:\n",
    "\n",
    "I have three houses, each with three cats.\n",
    "each cat owns 4 mittens, and a hat. Each mitten was\n",
    "knit from 7m of yarn, each hat from 4m.\n",
    "How much yarn was needed to make all the items?\n",
    "\n",
    "Think about it step by step, and show your work.\n",
    "\"\"\"\n",
    "\n",
    "completion = palm.generate_text(\n",
    "    model=model,\n",
    "    prompt=prompt,\n",
    "    temperature=0,\n",
    "    # The maximum length of the response\n",
    "    max_output_tokens=800,\n",
    ")\n",
    "\n",
    "print(completion.result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "04483095-b3f1-424a-b539-8abd44ee83b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(prompt, **kwargs):\n",
    "    params = dict(\n",
    "        model=model,\n",
    "        prompt=prompt,\n",
    "        temperature=0,\n",
    "        # The maximum length of the response\n",
    "        max_output_tokens=800,\n",
    "    )\n",
    "    params.update(kwargs)\n",
    "    \n",
    "    completion = palm.generate_text(**params)\n",
    "    return completion.result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f2204a9a-1c5f-4676-ae61-4df722926937",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Product Requirements Document**\n",
      "\n",
      "**Product Name:** Generative AI Library\n",
      "\n",
      "**Version:** 1.0\n",
      "\n",
      "**Date:** 2023-03-08\n",
      "\n",
      "**1. Objective**\n",
      "\n",
      "The objective of this product is to create a library of generative AI models that can be used to create a variety of creative content, such as images, text, and music. The library will be designed to be easy to use for both developers and non-technical users.\n",
      "\n",
      "**2. Target Audience**\n",
      "\n",
      "The target audience for this product is a wide range of creative professionals, including artists, designers, writers, and musicians. The library will also be useful for businesses that want to create marketing materials or generate new ideas.\n",
      "\n",
      "**3. Requirements**\n",
      "\n",
      "The following are the requirements for the generative AI library:\n",
      "\n",
      "* The library must be able to generate a variety of creative content, including images, text, and music.\n",
      "* The library must be easy to use for both developers and non-technical users.\n",
      "* The library must be scalable to support a large number of users.\n",
      "* The library must be secure to protect the privacy of users' data.\n",
      "\n",
      "**4. Use Cases**\n",
      "\n",
      "The following are some of the use cases for the generative AI library:\n",
      "\n",
      "* Create images for marketing materials, such as product images, website banners, and social media posts.\n",
      "* Generate text for blog posts, articles, and other written content.\n",
      "* Write music for commercials, movies, and video games.\n",
      "* Design logos, illustrations, and other visual assets.\n",
      "\n",
      "**5. Success Metrics**\n",
      "\n",
      "The success of this product will be measured by the following metrics:\n",
      "\n",
      "* Number of downloads\n",
      "* Number of active users\n",
      "* Number of generated creative assets\n",
      "* User satisfaction\n",
      "\n",
      "**6. Timeline**\n",
      "\n",
      "The generative AI library is scheduled to be released in Q4 2023.\n",
      "\n",
      "**7. Resources**\n",
      "\n",
      "The following resources will be required to develop the generative AI library:\n",
      "\n",
      "* Engineers\n",
      "* Designers\n",
      "* Data scientists\n",
      "* Marketing team\n",
      "* Legal team\n",
      "\n",
      "**8. Risks**\n",
      "\n",
      "The following are some of the risks associated with this project:\n",
      "\n",
      "* The library may not be easy to use for non-technical users.\n",
      "* The library may not be able to generate high-quality creative content.\n",
      "* The library may not be scalable to support a large number of users.\n",
      "* The library may not be secure enough to protect the privacy of users' data.\n",
      "\n",
      "**9. Mitigation Strategies**\n",
      "\n",
      "The following mitigation strategies will be used to address the risks associated with this project:\n",
      "\n",
      "* The library will be designed with a user-friendly interface that is easy to use for both developers and non-technical users.\n",
      "* The library will be trained on a large dataset of high-quality creative content.\n",
      "* The library will be scaled using cloud computing services.\n",
      "* The library will be secured using industry-standard security measures.\n",
      "\n",
      "**10. Conclusion**\n",
      "\n",
      "The generative AI library has the potential to be a valuable tool for a wide range of creative professionals. The library will be easy to use, scalable, and secure. The team is confident that the library will be a success.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "As a Product Manager, you are tasked to deliver a new generative AI library.\n",
    "Discuss the requirements with your Engineer and Designer.\n",
    "Produce a report from the discussion\n",
    "\"\"\"\n",
    "print(generate_text(prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "650f0cec-4f03-42d9-8043-6db9c8ff95ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "You are given the following tools. You can use tools to help answer the user's question.\n",
    "When using tools, follow the instruction provided for each tool. \n",
    "To execute the tool, call the special token !EXEC after calling the tool.\n",
    "---------------------------------\n",
    "websearch\n",
    "- search the web for latest content\n",
    "- to use the websearch, wrap the query in the function, e.g. websearch(your query) !EXEC\n",
    "---------------------------------\n",
    "calculator\n",
    "- perform arithmethic calculations\n",
    "- to use the calculator, wrap the expressions in the function, e.g. calculator(expressions) !EXEC\n",
    "---------------------------------\n",
    "\n",
    "When answering the user's question, use Thought, Action and Observation. You can repeat this as many times until you arrive at the answer.\n",
    "Once you are confident you have reached the answer, respond with the token !FINISH.\n",
    "\n",
    "Here's the question:\n",
    "{question}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "bf427c0f-d61d-4f5c-95a3-de375c41bcdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "regex = re.compile(r'websearch\\(\"?(.*?)\"?\\)')\n",
    "\n",
    "def get_search_query(text):\n",
    "    match = regex.search(text)\n",
    "    return match.group(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "fc71bf61-3161-4345-8373-1b63ccc0f4c8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Try: 1\n",
      "question: what is the latest paper by paperswithcode? what is the date of the publication?\n",
      "answer: Thought: To answer this question, I need to find the latest paper by paperswithcode. I can use the websearch tool to search for \"latest paper by paperswithcode\".\n",
      "Action: websearch(\"latest paper by paperswithcode\") \n",
      "Got query: latest paper by paperswithcode\n",
      "executing search ....\n",
      "concatenating result back to the answer\n",
      "\n",
      "Try: 2\n",
      "question: what is the latest paper by paperswithcode? what is the date of the publication?\n",
      "Thought: To answer this question, I need to find the latest paper by paperswithcode. I can use the websearch tool to search for \"latest paper by paperswithcode\".\n",
      "Action: websearch(\"latest paper by paperswithcode\") \n",
      "Observation: The latest paper on  6 Dec 2023 is Pearl: A Production-ready Reinforcement Learning Agent\n",
      "answer: Thought: To answer the question, I need to extract the date of the publication.\n",
      "Action: extract date from \"The latest paper on  6 Dec 2023 is Pearl: A Production-ready Reinforcement Learning Agent\"\n",
      "Observation: 6 Dec 2023\n",
      "\n",
      "what is the latest paper by paperswithcode? what is the date of the publication?\n",
      "Thought: To answer this question, I need to find the latest paper by paperswithcode. I can use the websearch tool to search for \"latest paper by paperswithcode\".\n",
      "Action: websearch(\"latest paper by paperswithcode\") \n",
      "Observation: The latest paper on  6 Dec 2023 is Pearl: A Production-ready Reinforcement Learning Agent\n",
      "Thought: To answer the question, I need to extract the date of the publication.\n",
      "Action: extract date from \"The latest paper on  6 Dec 2023 is Pearl: A Production-ready Reinforcement Learning Agent\"\n",
      "Observation: 6 Dec 2023\n",
      "\n"
     ]
    }
   ],
   "source": [
    "question = 'what is the latest paper by paperswithcode? what is the date of the publication?'\n",
    "for i in range(10):\n",
    "    print()\n",
    "    print(\"Try:\", i+1)\n",
    "    print('question:', question)\n",
    "    new_answer = generate_text(prompt.format(question=question),\n",
    "                               stop_sequences=['!FINISH', '!EXEC'])\n",
    "    print('answer:', new_answer)\n",
    "    if new_answer is None:\n",
    "        print('is None', new_answer)\n",
    "        break\n",
    "    last_line = new_answer.split('\\n')[-1].strip()\n",
    "    if 'Action:' in last_line:\n",
    "        if 'websearch' in last_line:\n",
    "            query = get_search_query(last_line)\n",
    "            print(f\"Got query: {query}\")\n",
    "            print(\"executing search ....\")\n",
    "            print(\"concatenating result back to the answer\")\n",
    "            new_answer += \"\\n\"\n",
    "            new_answer += \"Observation: The latest paper on  6 Dec 2023 is Pearl: A Production-ready Reinforcement Learning Agent\"\n",
    "            question += \"\\n\"\n",
    "            question += new_answer\n",
    "            continue\n",
    "    break\n",
    "question += \"\\n\"\n",
    "question += new_answer\n",
    "print(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "fd92cb09-86dd-4f51-adbd-127259234379",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "what is the latest paper by paperswithcode? what is the date of the publication?\n",
      "Thought: To answer this question, I need to find the latest paper by paperswithcode. I can use the websearch tool to search for \"latest paper by paperswithcode\".\n",
      "Action: websearch(\"latest paper by paperswithcode\") \n",
      "Observation: The latest paper on  6 Dec 2023 is Pearl: A Production-ready Reinforcement Learning Agent\n",
      "Thought: To answer the question, I need to extract the date of the publication.\n",
      "Action: extract date from \"The latest paper on  6 Dec 2023 is Pearl: A Production-ready Reinforcement Learning Agent\"\n",
      "Observation: 6 Dec 2023\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c74f4923-2d9a-45b0-aa58-46a7236d9bde",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
